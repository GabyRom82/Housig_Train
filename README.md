<h1 align="center"> DATA ANALYST portfolio (predicci√≥n de precios) </h1> 
<p align="center">
  <img width="275" height="183" alt="image" src="https://github.com/user-attachments/assets/889be6d9-db76-4e55-8f02-55a19b04b840" />
</p>

# DESCRIPCI√ìN DEL PROYECTO
   ## Predicci√≥n y An√°lisis de Precios de Casas  

Este repositorio contiene mi **primer proyecto de an√°lisis de datos**, donde aplico **Python** y **SQL** para explorar, limpiar y analizar un dataset de precios de viviendas.  
El proyecto incluye la implementaci√≥n de un **modelo de Regresi√≥n** para la **predicci√≥n de precios de casas**.  

---

  ## Objetivos  

- Realizar **an√°lisis exploratorio de datos (EDA)** para comprender qu√© variables influyen en el precio de las casas.  
- Implementar **t√©cnicas de regresi√≥n** para segmentar viviendas en grupos con caracter√≠sticas similares.  
- Construir un **modelo predictivo b√°sico** como introducci√≥n a modelos de machine learning para predicci√≥n de precios.  
- Desarrollar habilidades pr√°cticas con Python y librer√≠as de an√°lisis de datos.  

---

 ## Herramientas y Tecnolog√≠as  

- **Lenguajes:** Python
- **Librer√≠as principales:**  
  - pandas, numpy ‚Üí limpieza y manipulaci√≥n de datos  
  - matplotlib, seaborn ‚Üí visualizaci√≥n  
  - scikit-learn ‚Üí regresi√≥n y modelo predictivo  
- **Entorno:** Google Colab / Jupyter Notebook  

---
# ESTADO DEL PROYECTO 
<h4 align="center">
:<img width="225" height="225" alt="image" src="https://github.com/user-attachments/assets/b25df3b6-ee43-4817-9c9b-67480bff8a15" />
 Proyecto terminado 
</h4>



# ESTRUCTURA DEL PROYECTO  

## Portafolio_Housig_PredictionTraining
Se realiza un an√°lisis de datos, para identificaciar las variables m√°s importantes que afectan a la estimaci√≥n de precios. Lo primero a realizar es el an√°lisis general del *BASE DE DATOS* original, para hacer un an√°lisis exploratorio, se revisa las correlaciones para identificar y elegir las variables  con la mayor correlaci√≥n, posteriormente se realiza un *DataFrame* con los datos que vamos a utilizar, y a las variables a las que vamos a aplicar el modelo de regresi√≥n. 

La base de datos original es proveniente de Kaggle. Se utiliza un modelo de ML basado en modelos de regressi√≥n (Decision Tree Regressor, Random Forest Regressor). Este an√°lisis me sirve para mostrar habilidades de an√°lisis de datos, comprensi√≥n b√°sica de modelos de automatizaci√≥n de ML. Uso de  Python, SQL, elaboraci√≥n de Dashboards, y Matplotlib.

## Contexto de los datos
Esta base de datos contienen informaci√≥n del censo de las casas en California de 1990. 
Entonces este trabajo no va aprdecir los datos actuales de las casas, fue utilizado en el segundo cap√≠tulo del libro de Aur√©lien G√©ron, "Aprendizaje autom√°tico pr√°ctico con Scikit-Learn y TensorFlow". Se utiliza como ejercicio e introducci√≥n a la implementaci√≥n de algoritmos de aprendizaje autom√°tico. Pero la base disponible en Kaggle es un una versi√≥n modificada del conjunto de datos de Vivienda de California, disponible en la p√°gina de Lu√≠s Torgo (Universidad de Oporto).

Objetivo del an√°lisis:
                       * A partir de los datos hist√≥ricos utilizar t√©cnicas de predicci√≥n para obtener un precio apropiado para una casa en funci√≥n de las variables que inciden en mayor medida en el precio.
                       * Creaci√≥n de un modelo utilizando datos disponibles para pronosticar los precios de casa.
          
## Entendimiento del negocio
Aunque este an√°lisis es solamente como ejercicio, y demostraci√≥n de habilidades, el an√°lisis de este Dataset ayuda a ver como un buen an√°lsis de datos, puede generar conocimiento valioso para toma de desiciones en diferentes sectores, ayudando a :

***Objetivo comercial:*** Poder predecir precios de casas de manera autom√°tica, bas√°ndose en algunas caracter√≠sticas determinadas. 
Mejorar la toma de decisiones
Reducir de costos
Mejorar la calidad de servicio
Reducir de errores

***Objetivo de an√°lisis y miner√≠a de datos:*** A partir de los datos hist√≥ricos se analizan las variables disponibles para identificar cu√°les influyen de manera predominante en el objeto de estudio. Con base en este an√°lisis, se aplican t√©cnicas de predicci√≥n (modelo de regresi√≥n) que permiten estimar un precio adecuado de una vivienda en funci√≥n de las variables que mayor impacto tienen en su valor..


## üìÇ C√≥digo, Instalaci√≥n y Ejecuci√≥n  

Este an√°lisis fue realizado en **Google Colab** con **Python**, por lo que es necesario contar con las siguientes librer√≠as y herramientas instaladas.

### üß∞ Requisitos
- Python 3.10+ (recomendado)  
- Git  
- Google Colab (o Jupyter Notebook si trabajas localmente)  

---

### üöÄ Instalaci√≥n

1. **Clona el repositorio**
```git clone https://github.com/TU_USUARIO/TU_REPO.git
cd TU_REPO

2. **Crea y activa un entorno virtual**
Windows
python -m venv .venv
.venv\Scripts\activate

macOS / Linux
python3 -m venv .venv
source .venv/bin/activate

3. **Instala las dependencias**
pip install -r requirements.txt

‚ñ∂Ô∏è Ejecuci√≥n
A) Script de Python
python src/main.py --config configs/base.yaml

B) Jupyter Notebook / Google Colab
jupyter lab
jupyter notebook

1. Abrir el archivo:
notebooks/EDA.ipynb

üìö Librer√≠as utilizadas
import sys
import matplotlib
import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd
import numpy as np
import sklearn
from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier
from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
from sklearn.metrics import confusion_matrix,ConfusionMatrixDisplay, classification_report
from sklearn.metrics import accuracy_score, f1_score
from sklearn.preprocessing import LabelEncoder
import pickle
import warnings

‚èπÔ∏è Salir del entorno
deactivate
```

## Desarolladora del proyecto

**GABRIELA ROMERO  MORENO** 
<img align="right" width="150" alt="Screenshot 2025-07-16 152132" src="https://github.com/user-attachments/assets/735c69ec-20b7-45d4-8646-1497d2e6e7f8" />


MAESTR√çA EN CIENCIAS  
ANALISTA DE DATOS CON M√ÅS DE 5 A√ëOS DE EXPERIENCIA EN ENTORNOS CIENT√çFICOS
EDUCATIVOS-ADMINISTRATIVOS. ESPECIALIZADA EN AN√ÅLISIS ESTAD√çSTICO, GESTI√ìN Y 
VISUALIZACI√ìN DE BASES DE DATOS.  



## Preparaci√≥n de los datos

  Revisamos nuestra base de datos para cerciorarnos que no hay valores nulos, ni valores repetidos en nuestra base de datos, y que esta quede limpia para poder aplicar correctamente el modelo.
  
  Debido a que la base de datos original presenta un alto grado de valores faltantes en la variable PooQC usada 99.520548, se reemplazan los valores faltantes por 0 y se agrega la columna que utilizamos en nuestra base ya sin nulos y limpia llamada PoolArea.

Imagen de la base original: <img width="920" height="596" alt="image" src="https://github.com/user-attachments/assets/457e177a-642d-44e0-bf73-752318263b96" />

Imagen de la base Clean_Data lista sin nulos

<img width="515" height="502" alt="image" src="https://github.com/user-attachments/assets/af967a70-9783-42b5-88b4-88333d3e078b" />
<img width="748" height="702" alt="image" src="https://github.com/user-attachments/assets/191b1497-cf52-45f5-83c5-5bcaef966e4b" />


Debido a que las variables que elegimos, todas soon num√©ricas, no hay necsidad de trasformar variables categ√≥ricas a num√©ricas. 

  


## An√°lisis Descriptivo

En la base de datos original, se ten√≠a un total de 81 variables , y 1460 datos. Una vez revisado los √≠ndices de correlaci√≥n, se determin√≥ aplicar el modelo solo a 8 variables con el √≠ndice m√°s alto de correlaci√≥n. 

La base de datos limpia, con las 8 variablesse ve de la siguiente forma: 
<img width="987" height="569" alt="image" src="https://github.com/user-attachments/assets/f0d2a882-c4ac-4257-8c06-6d5522f8e30a" />

posee las siguientes car√°cter√≠sticas: 

<img width="1116" height="453" alt="image" src="https://github.com/user-attachments/assets/ddf33cd6-a370-43d9-9df9-9f2ecf08ca23" />

<img width="830" height="649" alt="image" src="https://github.com/user-attachments/assets/50ea76e7-8a06-44d2-8148-3abedc9ad3b5" />

Y las correlaciones entre nuestra variable objetivo ('SalesPrice') y las dem[as variables> 

<img width="1364" height="422" alt="image" src="https://github.com/user-attachments/assets/d203087c-4bf6-41f0-b128-1b17a3e24672" />
<img width="956" height="434" alt="image" src="https://github.com/user-attachments/assets/da43afb4-2902-420c-96df-e9c2663b04c0" />



## MODELADO (aprendizaje supervisado, Regresi√≥n)

Se ***definen valores de X y Y*** para modelo de aprendizaje supervisado:
``` # Definir valores de X y Y para modelo de aprendizaje supervisado
X= df.drop(columns=['SalePrice']).values
y= df['SalePrice'].values
print(f'{X.shape=}')
print(f'{y.shape=}')
```

Al ser un modelo de **aprendizaje supervisado**, es decir, utiliza datos etiquetados para predecir el resultado, debemos *separar el conjunto de datos* en entrenamiento y prueba, con 70/30 para regresi√≥n.

<img width="877" height="260" alt="image" src="https://github.com/user-attachments/assets/b79b85e1-e0e7-4814-a983-8b33ed7c5047" />

 
 Para poder comparar dos prediccones distintas, utilizaremos dos modelos diferentes de aprendizaje supervisado: √°rbol de decisi√≥n para regresi√≥n y random forest. Mientras que un √Årbol de Decisi√≥n divide los datos para hacer predicciones de regresi√≥n (valor num√©rico) o clasificaci√≥n (categor√≠a), el modelo Random Forest mejora la precisi√≥n y reduce el sobreajuste combinando las predicciones de m√∫ltiples √°rboles de decisi√≥n, obteniendo el resultado final mediante el promedio (regresi√≥n) o la votaci√≥n mayoritaria (clasificaci√≥n).

¬øPor qu√© es √∫til usar ambos en el proyecto?

1.Comparaci√≥n de desempe√±o: √Årbol de decisi√≥n ‚Üí modelo base, sencillo de entender. Random Forest ‚Üí modelo m√°s robusto, ideal para ver si mejora la precisi√≥n.
2.Balance entre interpretabilidad y rendimiento: Con el √°rbol puedes mostrar las reglas de decisi√≥n (√∫til para explicar a no t√©cnicos). Con Random Forest tienes un modelo m√°s confiable para predicciones reales.
3.Importancia de variables: Ambos permiten medir qu√© variables afectan m√°s al precio (ej: superficie, ubicaci√≥n, n√∫mero de habitaciones). Esto te ayuda a justificar el an√°lisis adem√°s de la predicci√≥n.

<img width="1271" height="482" alt="image" src="https://github.com/user-attachments/assets/0723b196-f8a2-49ab-a344-75d8743b788b" />

Entonces ahora  se van a **definir** los modelos

``` # Definir modelo: √°rbol de decisi√≥n para regresi√≥n
mod_dt_reg= DecisionTreeRegressor(max_depth=2,random_state=0)
#Entrenar
mod_dt_reg.fit(x_train, y_train)
#Predecir
y_pred_dt_reg= mod_dt_reg.predict(x_test)

#Definir el modelo Random Forest para regresi√≥n
mod_rf_reg= RandomForestRegressor(max_depth=2, random_state=0)

#Entrenar
mod_rf_reg.fit(x_train, y_train)

# Predecir
y_pred_rf_reg = mod_rf_reg.predict(x_test)
```


Una vez definidos los modelos, podemos pasar  a ***EVALUACI√ìN Y ENTRENAMIENTO*** de los modelos.

Para explicar esta parte, primero debemos entender que cuando entrenamos un modelo supervisado (en este caso de regresi√≥n), necesitamos medir qu√© tan bien predice sobre datos que no ha visto. En nuestro caso cuando la variable a predecir es num√©rica, como el precio de casas, la regresion mide qu√© tan lejos est√°n las predicciones de los valores reales. 

M√©tricas comunes:
MAE (Mean Absolute Error / Error Absoluto Medio)
MSE (Mean Squared Error / Error Cuadr√°tico Medio)
RMSE (Root Mean Squared Error / Ra√≠z del Error Cuadr√°tico Medio)

En el ejemplo que presento aqu√≠, el √∫ltimo m√©todo RMSE es el que defino como m√©todo de evaluaic√≥n, y se determina con la siguiente formula:   <img width="403" height="88" alt="image" src="https://github.com/user-attachments/assets/cea53246-08d9-4e85-9bbc-8f997c5c9db0" />

Ya que mide el error en las mismas unidades de la variable. Es la m√©trica m√°s usada en √°rboles de decisi√≥n y random forest porque:
*Da una idea clara de cu√°n lejos, en promedio, est√° la predicci√≥n del valor real.
*Penaliza m√°s los errores grandes (por ejemplo: predecir una casa en 200,000 cuando vale 500,000).

üî∏ En espec√≠fico el RMSE en el √Årbol de Decisi√≥n para regresi√≥nes es √∫til porque:
1. Penaliza fuertemente errores grandes (importante en predicciones de precios), es decir,  durante el entrenamiento, el √°rbol de decisi√≥n ***se ajusta minimizando*** el RMSE en cada divisi√≥n.
2. Est√° en la misma escala de la variable (dinero, metros, etc.), lo que facilita la interpretaci√≥n.
3. Al evaluar el modelo, usamos RMSE en datos de prueba para ver qu√© tan bien generaliza.

Con esto quiero decir, en este ejercicio que si predecimos precios de casas y se obtiene un RMSE = 25,000, significa que en promedio, tu modelo se equivoca en ¬±25,000 d√≥lares respecto al precio real.

El codigo para poder evaluar los modelos:
```#Evaluar modelo de √°rbol de decisi√≥n para regresi√≥n: M√©todo RMSE
rmse_dt_reg= np.sqrt(mean_squared_error(y_test, y_pred_dt_reg))
print(f'RMSE √Årbol de decisi√≥n: {rmse_dt_reg: .2f}')

# Evaluar modelo de random forest para regresi√≥n
rmse_rf_reg = np.sqrt(mean_squared_error(y_test, y_pred_rf_reg))
print(f'{rmse_rf_reg = :.2f}')
```
Est√°s evaluaicones nos indican que para el modelo del √Årbol de decisi√≥n su RMSE:  48115.47, y para el modelo Random forest su RMSE = 45236.62, recordemos que el RMSE devuelve el error en las mismas unidades de la variable objetivo (en este caso d√≥lares), la interpretaci√≥n indica que cuanto m√°s bajo sea el RMSE, mejor es el modelo (menor error).

Adem√°s tenemos la evaluaci√≥n de las dem√°s metricas, que nos indican , de igual manera que el modelo de Random forest es mejor:
<img width="479" height="651" alt="image" src="https://github.com/user-attachments/assets/683db7af-2f88-4b09-9093-760d6698f3d0" />



üìä Comparaci√≥n de Modelos de Regresi√≥n
Al ver los valores de evaluaci√≥n de los dos modelos supervisados para la predicci√≥n de precios de vivienda: Decision Tree Regressor y Random Forest Regressor. Los resultados muestran que el Random Forest ofrece un mejor desempe√±o estad√≠stico frente al Decision Tree.
Este modelo presenta errores m√°s altos y solo explica el 66.8% de la variabilidad, por lo que es menos preciso y generaliza peor que el Random Forest.

‚úÖ Conclusi√≥n

El Random Forest Regressor es el modelo que m√°s se acerca a los valores reales, con menor error absoluto y cuadr√°tico y una mayor capacidad explicativa (R¬≤). Esto se debe a que, al combinar m√∫ltiples √°rboles de decisi√≥n, reduce la varianza y logra una predicci√≥n m√°s robusta frente a datos nuevos.Una vez que evaluamos que modelo es mejor, vamos a guardar los modelos para poder hacer las pruebas de predicci√≥n y comprobar que realmente el modelo que se ajusta mejor, es el modelo Random forest.

Una vez evaluados ambos modelos, los guardamos, con el c√≥digo:
```# Guardar modelo
modelo_rf= mod_rf_reg 
model_type= 'regresion'
library_version= 'rf_sklearn' + '_' + sklearn.__version__.replace('.','_')
model_name= model_type + '_' + library_version + '.pickle'

pickle.dump(modelo_rf, open("regresion_RandomForestRegressor.pkl", "wb"))

print(type(modelo_rf))
print('Saved model: ' + model_name)

# Guardar modelo
modelo_dt = mod_dt_reg
model_type = 'regression'
library_version = 'Decicion_TreeRegressor' + '_' + sklearn.__version__.replace('.','_')
model_name = model_type + '_' + library_version + '.pickle'

pickle.dump(modelo_dt, open("regresion_DecisionTreeRegressor.pkl", "wb"))

print(type(modelo_dt))
print('Saved model: ' + model_name)
```
Para poder proceder a las predicciones, con datos nuevos, y con los datos reales.

***PREDICCI√ìN**

Para poder hacer las predicciones, primero creamos una matriz de Numpy, para utilizar el modelo con datos nuevos:

```# Nuevos datos de [	OverallQual,	GrLivArea,	GarageArea,	TotalBsmtSF,	FullBath,	YearBuilt,	PoolArea	]
X_new = np.array([[  9,	1607,	192,	156,	1,	2015,	0]])
x_new1= np.array([[  7,	1710,	548,	856,	2,	2003,	0]])
x_new2= np.array([[6,	1262,	460,	1262,	2,	1976,	0]])
x_new3= np.array([[7,	1786,	608,	920,	2,	2001,	0]])
x_new4= np.array([[5,	1256,	276,	1256,	1,	1965,	0]])
```
En este caso x_new1 y x_new3 corresponden a datos reales, para poder comparar y conocer realmente la precisi√≥n de la predicci√≥n en ambos modelos. Las predicciones las hacemos con el siguiente c√≥digopoemos verlas: 
 
<img width="706" height="477" alt="image" src="https://github.com/user-attachments/assets/bc9c913c-ae82-4f81-b077-029fb086dbc4" />

<img width="625" height="591" alt="image" src="https://github.com/user-attachments/assets/b8dc2c2e-64f0-4240-bca6-20b56f501591" />

























